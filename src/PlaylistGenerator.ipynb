{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random as rnd\n",
    "import pandas as pd \n",
    "\n",
    "import pgutils as pg\n",
    "import pgmath as pm\n",
    "import algorithm as al\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "root_dir = r'C:\\Users\\eleon\\PycharmProjects\\SM_Exam\\data\\yes_small'\n",
    "#root_dir = './data/yes_small'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#test_data=[]\n",
    "with open(os.path.join(root_dir, 'test.txt')) as f:\n",
    "#with open(root_dir + \"\\\\test.txt\", \"r\") as f:\n",
    "\n",
    "    test_data = f.readlines()\n",
    "    \n",
    "test_dataset = pg.data_to_list(test_data[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#train_data=[]\n",
    "with open(os.path.join(root_dir,\"train.txt\"), \"r\") as f:\n",
    "    train_data = f.readlines()\n",
    "    \n",
    "#train_dataset = pg.data_to_list(train_data[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "song_hash = pd.read_csv(os.path.join(root_dir,\"song_hash.txt\"), sep=\"\\t\", header=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# setting parameters\n",
    "dimension = 2#rnd.choice([2, 5,10,25,50,100])\n",
    "# regularization parameter set by cross validation\n",
    "lam = rnd.choice([0.0001, 0.001, 0.01, 0.1, 1, 10, 20, 50, 100, 500, 1000])\n",
    "# regularization parameter for dual point model\n",
    "nu = rnd.choice([0, lam])\n",
    "# threshold for landmark dimension\n",
    "r = 0.2\n",
    "# number of landmark\n",
    "n_landmarks = 3#50\n",
    "# num iteration 100 o 200\n",
    "n_iter = 60 #rnd.choice([100, 200])\n",
    "# tau predefined learning rate\n",
    "tau = 0.5"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "toy_dataset=[[0,6,3,2,1,4,2],[2,0,6,5,6,3,0],[0,5,2,1,6],[5,6,2],[6,5,2,3,5,6,2]]\n",
    "\n",
    "songs = 7\n",
    "transition_matrix = pg.transition_count(songs, toy_dataset)\n",
    "position = np.random.rand(songs, dimension)\n",
    "num_transition = np.sum(transition_matrix)\n",
    "params = pm.AlgParams(lam, nu, tau, num_transition, n_landmarks, r, dimension, n_iter)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "X = al.single_point_algorithm(songs, transition_matrix, params)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "dummy_landmarks = [[i for i in range(songs)] for j in range(songs)]\n",
    "d2 = pm.Distances.delta(X)\n",
    "prob_matrix = np.exp(-d2)/pm.Distances.zeta(d2,X,dummy_landmarks)\n",
    "cum_sum = np.sum(prob_matrix, axis=1)\n",
    "prob_matrix = prob_matrix / cum_sum"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "[[0.16574914 0.14384048 0.14884891 0.13562863 0.14424961 0.14099463\n",
      "  0.1349401 ]\n",
      " [0.12643577 0.18856559 0.1157633  0.13465182 0.11941971 0.11501597\n",
      "  0.13797652]\n",
      " [0.14570234 0.12891484 0.16932864 0.12855955 0.14501758 0.15791592\n",
      "  0.12752357]\n",
      " [0.13805281 0.15592555 0.13368336 0.16283861 0.13985282 0.13773493\n",
      "  0.1615264 ]\n",
      " [0.14915748 0.140481   0.15318993 0.14207176 0.16029533 0.15338883\n",
      "  0.14092887]\n",
      " [0.12890582 0.11962978 0.14749423 0.12371438 0.13562299 0.18129311\n",
      "  0.12304612]\n",
      " [0.13558749 0.15772298 0.13090258 0.15945136 0.13694562 0.13523109\n",
      "  0.16495773]]\n",
      "[1.0142515  0.93782868 1.00296244 1.02961449 1.03951321 0.95970644\n",
      " 1.02079887]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print(prob_matrix)\n",
    "print(np.sum(prob_matrix, axis=1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "11.0\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "toy_test=[[0,4,5,3,6],[4,3,2,6],[0,2,1,0,5]]\n",
    "# evaluate test performance using the average log-likelihood as metric\n",
    "# it is defined as log(Pr(d_test))/n_test)\n",
    "# n_test number of transition in the test set\n",
    "songs = 7 #len(song_hash)\n",
    "n_test = np.sum(pg.transition_count(songs,toy_test))\n",
    "print(n_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "-1.975226823881699\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import math as mt\n",
    "def log_like(test_set, probability_matrix):\n",
    "    count=0\n",
    "    for i in range(len(test_set)):\n",
    "        for predecessor, successor in zip(test_set[i][:-1], test_set[i][1:]):\n",
    "            count = count + mt.log(probability_matrix[predecessor, successor])\n",
    "            \n",
    "    return count\n",
    "    \n",
    "    \n",
    "evaluation = log_like(toy_test,prob_matrix) /n_test\n",
    "print(evaluation)\n",
    "#result = sum( sum(dimension.D[s, i.index()] ) for i in range(len(test_dataset)))  "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}