{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-48ad2b55c6d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpgutils\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/PGenerator/pgutils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpgmath\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpgm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/PGenerator/pgmath.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mDistances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecordclass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mZ\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mD\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: function() argument 1 must be code, not str"
     ],
     "ename": "TypeError",
     "evalue": "function() argument 1 must be code, not str",
     "output_type": "error"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math as mt\n",
    "import os\n",
    "import random as rnd\n",
    "\n",
    "import pgutils as pg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "#root_dir = \".\\\\data\\\\yes_small\"\n",
    "root_dir = './data/yes_small'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-58d1d5d206cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtest_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtest_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_to_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pg' is not defined"
     ],
     "ename": "NameError",
     "evalue": "name 'pg' is not defined",
     "output_type": "error"
    }
   ],
   "source": [
    "test_data=[]\n",
    "with open(os.path.join(root_dir, \"test.txt\"), \"r\") as f:\n",
    "    test_data=f.readlines()\n",
    "    \n",
    "test_dataset = pg.data_to_list(test_data[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-1d8b67802687>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtrain_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_to_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pg' is not defined"
     ],
     "ename": "NameError",
     "evalue": "name 'pg' is not defined",
     "output_type": "error"
    }
   ],
   "source": [
    "train_data=[]\n",
    "with open(os.path.join(root_dir,\"train.txt\"), \"r\") as f:\n",
    "    train_data=f.readlines()\n",
    "    \n",
    "train_dataset = pg.data_to_list(train_data[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "song_hash = pd.read_csv(os.path.join(root_dir,\"song_hash.txt\"), sep=\"\\t\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0                                                  1  \\\n",
      "0        0                       Gucci Time (w\\/ Swizz Beatz)   \n",
      "1        1  Aston Martin Music (w\\/ Drake & Chrisette Mich...   \n",
      "2        2                      Get Back Up (w\\/ Chris Brown)   \n",
      "3        3                 Hot Toddy (w\\/ Jay-Z & Ester Dean)   \n",
      "4        4                                       Whip My Hair   \n",
      "...    ...                                                ...   \n",
      "3163  3163                                    Christmas Canon   \n",
      "3164  3164  Happy Xmas (War Is Over) (w\\/ The Harlem Commu...   \n",
      "3165  3165                    All I Want For Christmas Is You   \n",
      "3166  3166                                   Jingle Bell Rock   \n",
      "3167  3167                           Do You Hear What I Hear?   \n",
      "\n",
      "                             2  \n",
      "0                   Gucci Mane  \n",
      "1                    Rick Ross  \n",
      "2                         T.I.  \n",
      "3                        Usher  \n",
      "4                       Willow  \n",
      "...                        ...  \n",
      "3163  Trans-Siberian Orchestra  \n",
      "3164               John Lennon  \n",
      "3165              Mariah Carey  \n",
      "3166   Daryl Hall & John Oates  \n",
      "3167           Whitney Houston  \n",
      "\n",
      "[3168 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "#print(test_data[0].split(\" \")[:-1])\n",
    "#print(train_data[3].split(\" \")[:-1])\n",
    "#print(song_hash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def landmarkInitialization(n_landmarks, S, D2_mat):\n",
    "    landmarks=rn.sample(range(S))\n",
    "    distance=[D2_mat[s,l] for l in range(n_landmarks)]\n",
    "    C=[[] for i in range(n_landmarks)]\n",
    "    for s in range(S):\n",
    "        if min(distance)==D2_mat[s,i]:\n",
    "            C[i].append(s)\n",
    "    return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def landmarkThresholdExtention(S,r,n_landmarks,C):\n",
    "    for s in S:\n",
    "        for i in range(n_landmarks):\n",
    "            for l in range(S):\n",
    "                if (s in C[i] & l not in C[i] & len(C[i])/len(S)<r):\n",
    "                    C[i].append(min(D2_mat[s,l]))\n",
    "    return C[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateLandmarks(r,S,C,n_landmarks,D2_mat):\n",
    "    C=landmarkInitalization(n_landmarks, S, D2_mat)\n",
    "    C_r=landmarkThresholdExtention(S,r,n_landmarks,C)\n",
    "    return C_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''            \n",
    "def updateLandmarks(r,S, C):\n",
    "    for i in range(S):\n",
    "        distance= np.array([D2_mat[i,l] for l in range(n_landmarks)])\n",
    "        minElem = landmarks[i][np.argmin(distance)]\n",
    "        if minElem is not in C[i]:\n",
    "            C[i].append(minElem)\n",
    "    return C\n",
    "\n",
    "assign each song to the nearest landmark\n",
    "C=landmarkInizialization(r,n_landmarks,S,T)\n",
    "def landmarkGenerator(S):\n",
    "     landmarks=rnd.sample(range(S), 50)\n",
    "     C=[[] for i in range( len(landmarks))]\n",
    "    for i in range(len(landmarks)):\n",
    "        C[i].append(landmarks[i])\n",
    "        for s in range(S):\n",
    "            distance=[D2_mat[s,l] for l in range(len(landmarks))]\n",
    "            for i in range(len(landmarks)):\n",
    "                if min(distance)==D2_mat[s,i]:\n",
    "                       C[i].append(s)\n",
    "    return C\n",
    "\n",
    "def clustering(s,r):\n",
    "    #una volta importato il dataset con le canzoni S_set verrá sostitiuto\n",
    "    S_set=[i for i in range(S)]\n",
    "    C_r=C\n",
    "    threshold=0\n",
    "    for i in range(len(landmarks)):\n",
    "        if s in C[i]:\n",
    "            T=list(set(S_set)-set(C[i]))\n",
    "            threshold=len(C_r[i])/len(S)\n",
    "            for t in T:\n",
    "                if threshold<r:\n",
    "                    C_r[i].append(min(D2_mat[s,t] for t in T))\n",
    "                    T.remove(t)\n",
    "                    threshold=len(C_r[i])/len(T)\n",
    "    return C_r\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#definition of the \n",
    "from numpy import linalg as LA\n",
    "def delta2(U,V):\n",
    "    D_2=np.zeros((S,S))\n",
    "    for i in range(S):\n",
    "        for j in range(S):\n",
    "            D_2[i][j]=LA.norm(U[i]-V[j])\n",
    "    return D_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zeta2(U, V, D_2):\n",
    "    Z_2=np.zeros(S)\n",
    "    for idx in range(S):\n",
    "        sum_terms = np.array([D_2[idx,l] for l in range(S)])\n",
    "        Z_2[idx]=sum(np.exp(-(sum_terms**2)))\n",
    "    return Z_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#non va invertito U e V?\n",
    "def difMat(U,V,S,d):\n",
    "    dif_mat = np.empty((S,S,d))\n",
    "\n",
    "    for i in range(S):\n",
    "        for j in range(S):\n",
    "            dif_mat[i,j,:] = V[i] - U[j]\n",
    "    return dif_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def dlU(a,b,p,Z_2,D_2, dif_mat):\n",
    "    if a!=p:\n",
    "        return 0\n",
    "    s_term = np.array([mt.exp(-D_2[a,l]**2)*dif_mat[a,l,:] for l in range(S)])\n",
    "    return 2*(-dif_mat[a,b,:]+sum(s_term)/Z_2[a])       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dlV(a,b,q,Z_2,D_2, dif_mat):\n",
    "    if b!=q:\n",
    "        return 0\n",
    "    return 2*(dif_mat[a,b,:]-(mt.exp(-D_2[a,q]**2)*dif_mat[a,q,:])/Z_2[a])      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as rnd\n",
    "#da aggiungere valori\n",
    "l= 0.01#rnd.choice([0.0001, 0.001, 0.01, 0.1, 1, 10, 20, 50, 100, 500, 1000])\n",
    "print('value of lamda', l)\n",
    "nu=l#rnd.choice([0,l])\n",
    "print('value of nu', nu)\n",
    "    \n",
    "def doU(V,U,p):\n",
    "    return 2*l*U[p]-2*nu*(V[p]-U[p])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doV(V,U,p):\n",
    "    return 2*l*V[p]+2*nu*(V[p]-U[p])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateU(S, Z2_vec, D2_mat, T, U_new, U_old, V_old, tau, N, dif_mat):\n",
    "    for s_p in range(S):\n",
    "        dev_term = np.array([T[s_p,b]*dlU(s_p, b, s_p,Z2_vec,D2_mat, dif_mat) for b in range(S)])\n",
    "        U_new[s_p]=U_old[s_p]+(tau/N)*(sum(dev_term) - doU(V_old, U_old,s_p))\n",
    "    return U_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateV(S, Z2_vec, D2_mat, T,U_old, V_new, V_old, tau, N, dif_mat):\n",
    "    for s_q in range(S):\n",
    "        V_q = V_old[s_q]\n",
    "        for s_p in range(S):\n",
    "            if s_p == s_q:\n",
    "                continue\n",
    "            dev_term = np.array([T[s_p,b]*dlV(s_p, b, s_q,Z2_vec,D2_mat, dif_mat) for b in range(S)])\n",
    "            V_q=V_q+(tau/N)*(sum(dev_term) - doV(V_old, U_old,s_p))\n",
    "        V_new[s_q] = V_q\n",
    "    return V_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D2_mat = delta2(U_old,V_old)\n",
    "zeta2(U_old, V_old, D2_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U_old = np.random.rand(S,d)\n",
    "U_new = np.empty_like(U_old)\n",
    "V_old = np.random.rand(S,d)\n",
    "V_new = np.empty_like(V_old)\n",
    "#tau predefined learning rate\n",
    "tau = 0.5\n",
    "#number of transitions in the training set\n",
    "N=np.sum(T)\n",
    "\n",
    "#try for 100-200 iterations\n",
    "for k in range(20):\n",
    "    \n",
    "    D2_mat = delta2(U_old,V_old)\n",
    "    Z2_vec = zeta2(U_old, V_old, D2_mat)\n",
    "    dif_mat = difMat(U_old, V_old, S, d)\n",
    "    \n",
    "    #print(Z2_vec)\n",
    "    \n",
    "    updateU(S, Z2_vec, D2_mat, T, U_new, U_old, V_old, tau, N, dif_mat)\n",
    "    updateV(S, Z2_vec, D2_mat, T, U_old, V_new, V_old, tau, N, dif_mat)\n",
    "    \n",
    "    U_new, U_old = U_old, U_new\n",
    "    V_new, V_old = V_old, V_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('U after updating', U_old[0:10])\n",
    "print('U before updating', U_new[0:10])\n",
    "print('V after updating', V_old[0:10])\n",
    "print('V before updating', V_new[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model single point\n",
    "U_old = np.random.rand(S,d)\n",
    "U_new = np.empty_like(U_old)\n",
    "V_old = U_old\n",
    "V_new = np.empty_like(V_old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimization:\n",
    "\n",
    "n_landmarks = 5\n",
    "landmarks = []\n",
    "#consider a subset C_i as possible successor for song s_i\n",
    "#randomly pick n number of song(50)called landmarks\n",
    "for s in range(S):\n",
    "    landmarks.append(rnd.sample(range(S), n_landmarks)) #senza ripetizione\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(landmarks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#C=[[] for i in range(S)]\n",
    "#va fatta al'inizio del alg e basta\n",
    "#bisogna mettere i sucessori dal training set\n",
    "\n",
    "def updateLandmarks(r,S,C,D2):\n",
    "    for i in range(S):\n",
    "        distance= np.array([D2[i,l] for l in range(n_landmarks)])\n",
    "        minElem = landmarks[i][np.argmin(distance)]\n",
    "        if minElem not in set(C[i]):\n",
    "            C[i].append(minElem)\n",
    "    return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assign each song to the nearest landmark\n",
    "C=landmarkInizialization(r,n_landmarks,S,T)\n",
    "def landmarkGenerator(S):\n",
    "    landmarks=rnd.sample(range(S), 50)\n",
    "    C=[[] for i in range( len(landmarks))]\n",
    "    for i in range(len(landmarks)):\n",
    "        C[i].append(landmarks[i])\n",
    "        for s in range(S):\n",
    "            distance=[D2_mat[s,l] for l in range(len(landmarks))]\n",
    "            for i in range(len(landmarks)):\n",
    "                if min(distance)==D2_mat[s,i]:\n",
    "                       C[i].append(s)\n",
    "    return C\n",
    "\n",
    "def clustering(s,r):\n",
    "    #una volta importato il dataset con le canzoni S_set verrá sostitiuto\n",
    "    S_set=[i for i in range(S)]\n",
    "    C_r=C\n",
    "    threshold=0\n",
    "    for i in range(len(landmarks)):\n",
    "        if s in C[i]:\n",
    "            T=list(set(S_set)-set(C[i]))\n",
    "            threshold=len(C_r[i])/len(S)\n",
    "            for t in T:\n",
    "                if threshold<r:\n",
    "                    C_r[i].append(min(D2_mat[s,t] for t in T))\n",
    "                    T.remove(t)\n",
    "                    threshold=len(C_r[i])/len(T)\n",
    "    return C_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#specify a threshold r in [0,1] percentage songs in the data set included in the calculos of the log likelihood\n",
    "#r=rnd.choice(np.arange(0,1,0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustering(s,r):\n",
    "    #una volta importato il dataset con le canzoni S_set verrá sostitiuto\n",
    "    S_set=[i for i in range(S)]\n",
    "    C_r=C\n",
    "    threshold=0\n",
    "    for i in range(len(landmarks)):\n",
    "        if s in C[i]:\n",
    "            T=list(set(S_set)-set(C[i]))\n",
    "            threshold=len(C_r[i])/len(S)\n",
    "            for t in T:\n",
    "                if threshold<r:\n",
    "                    C_r[i].append(min(D2_mat[s,t] for t in T))\n",
    "                    T.remove(t)\n",
    "                    threshold=len(C_r[i])/len(T)\n",
    "    return C_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zeta2_r(a, U, V, D_2,C_r):\n",
    "    Z_r=np.zeros(S)\n",
    "    for i in range(len(landmarks)):\n",
    "        if a in C_r[i]:\n",
    "            for idx in range(len(C_r[i])):\n",
    "                sum_terms = np.array([D_2[idx,l] for l in range(S)])\n",
    "                Z_r[idx]=sum(np.exp(-(sum_terms**2)))\n",
    "    return Z_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dlU_r(a,b,p,Z_r,D_2,dif_mat,C_r):\n",
    "    if a!=p:\n",
    "        return 0\n",
    "    for i in range(len(landmarks)):\n",
    "        if p in C_r[i]:\n",
    "            s_term = np.array([mt.exp(-D_2[a,l]**2)*dif_mat[a,l,:] for l in range(len(C_r[i]))])\n",
    "    return 2*(-dif_mat[a,b,:]+sum(s_term)/Z_r[a])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dlV(a,b,q,Z_r,D_2, dif_mat):\n",
    "    if b!=q:\n",
    "        return 0\n",
    "    return 2*(dif_mat[a,b,:]-(mt.exp(-D_2[a,q]**2)*dif_mat[a,q,:])/Z_r[a])      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U_old = np.random.rand(S,d)\n",
    "U_new = np.empty_like(U_old)\n",
    "V_old = np.random.rand(S,d)\n",
    "V_new = np.empty_like(V_old)\n",
    "#tau predefined learning rate\n",
    "tau = 0.5\n",
    "#number of transitions in the training set\n",
    "N=np.sum(T)\n",
    "\n",
    "#try for 100-200 iterations\n",
    "for k in range(200):\n",
    "    \n",
    "    D2_mat = delta2(U_old,V_old)\n",
    "    Zr_vec = zeta2_r(a,U_old, V_old, D2_mat,C_r)\n",
    "    dif_mat = difMat(U_old, V_old, S, d)\n",
    "    \n",
    "    #print(Z2_vec)\n",
    "    \n",
    "    updateU(S, Zr_vec, D2_mat, T, U_new, U_old, V_old, tau, N, dif_mat)\n",
    "    updateV(S, Zr_vec, D2_mat, T,U_old, V_new, V_old, tau, N, dif_mat)\n",
    "    \n",
    "    U_new, U_old = U_old, U_new\n",
    "    V_new, V_old = V_old, V_new\n",
    "    if k==10:\n",
    "        landmarkGenerator(S)\n",
    "#empirically update landmarks every 10 iterations\n",
    "#A iteration means a full pass on the training dataset.\n",
    "#fix the landmarks after 100 iteration to ensure convergence   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute and print the log-likelihood\n",
    "#We evaluate test performance using the average log-likelihood as our metric. \n",
    "#It is deﬁned as log(Pr(Dtest))/Ntest, \n",
    "#where Ntest is the number of transitions in test set\n",
    "\n",
    "#calculus of matrix T[a,b]== transition from s_a to s_b (in the test set)\n",
    "T_test=np.zeros((S,S))\n",
    "for i in range(len(test_dataset)):\n",
    "    for j in range(len(test_dataset[i])-1):\n",
    "        a=test_dataset[i][j];\n",
    "        b=test_dataset[i][j+1];\n",
    "        T_test[a][b]=T_test[a][b]+1\n",
    "\n",
    "N_test=np.sum(T_test)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1191279.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setto i parametri\n",
    "d=5;\n",
    "S=max([])\n",
    "l=rnd.choice([0.0001, 0.001, 0.01, 0.1, 1, 10, 20, 50, 100, 500, 1000])\n",
    "ni=rnd.choice([0,l])\n",
    "r=8\n",
    "n_landmarks=50\n",
    "n_iters=rnd.choice([100,200])\n",
    "tollerance=#da definire\n",
    "\n",
    "def EMC(song_hash,train_dataset,r,n_landmarks):\n",
    "    #1,definisco le funzioni di inizializzazione\n",
    "    S=len(song_hash[0].values)\n",
    "    U_old=np.random.rand(S,d)\n",
    "    V_old=np.random.rand(S,d)\n",
    "    U_new=np.empty_like(U_old)\n",
    "    V_new=np.empty_like(V_old)\n",
    "    T=pg.transition_count(S,train_dataset)\n",
    "    C=landmarkInizialization(r,n_landmarks,S,T)\n",
    "    C_rs=landmarkThresholdExtention(S,r,n_landmarks,C)    \n",
    "    \n",
    "    for iter in range(n_iters):\n",
    "        #2,update dei landmarks\n",
    "        if (iter%10==0 & iter<100):\n",
    "            C=updateLandmarks(r,S,C)\n",
    "        #3,Update U e V (new or old?)\n",
    "        U_old=update(U_old)\n",
    "        V_old=update(V_old)\n",
    "        #4,criterio d'arresto\n",
    "        if (stopCriteria(U_new,U_old)>tollerance | stopCriteria(V_new,V_old)>tollerance):\n",
    "            break\n",
    "        #5,swap matrix\n",
    "        U_new, U_old = U_old, U_new\n",
    "        V_new, V_old = V_old, V_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define delta_2(s_a, s_b):=norm(U(s_a)-V(s_b))\n",
    "import scipy.stats as stat\n",
    "import numpy as np\n",
    "from __future__ import division\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "\n",
    "#The value of the process are stored in a list X\n",
    "#The list of songs\n",
    "Songs=[1,2,3,4,5]\n",
    "#Start of the Markov chain\n",
    "X=[0]\n",
    "#Start of the time\n",
    "t=0\n",
    "#The music playlist\n",
    "Playlist=[]\n",
    "#while loop - the Markov chain did not reach 5 we go on\n",
    "while X[t]<5:\n",
    "    #Incrementation of time\n",
    "    t=t+1\n",
    "    #List of played songs\n",
    "    Playlist.append(np.random.choice(Songs))\n",
    "    #The number of unique songs played\n",
    "    X.append(len(np.unique(Playlist)))\n",
    "#Printing the path of the Markov chain\n",
    "print X\n",
    "#Printing the number of steps\n",
    "print len(X)-1\n",
    "\n",
    "# Part C\n",
    "Songs=[1,2,3,4,5]\n",
    "Paths=[]\n",
    "#Number of paths to generate\n",
    "PathNumber=10000\n",
    "for k in range(0,PathNumber,1):\n",
    "    #Start of the Markov chain\n",
    "    X=[0]\n",
    "    #Startn of the time\n",
    "    t=0\n",
    "    #TMusic playlist\n",
    "    Playlist=[]\n",
    "    #while loop - the Markov chain did not reach 5 we go on\n",
    "    while X[t]<5:\n",
    "        #Incrementation of time\n",
    "        t=t+1\n",
    "        #List of played songs\n",
    "        Playlist.append(np.random.choice(Songs))\n",
    "        #We look at the number of unique song played\n",
    "        X.append(len(np.unique(Playlist)))\n",
    "Paths.append(X)\n",
    "\n",
    "# Part D\n",
    "\n",
    "#Function for the mean of N\n",
    "def MeanT(Paths):\n",
    "    SampleT=[]\n",
    "    for element in Paths:\n",
    "        #The sample of Tau values\n",
    "        SampleT.append(len(element)-1)\n",
    "    #Return the sample mean\n",
    "    return np.mean(SampleT)\n",
    "\n",
    "#The sample mean for the generated paths\n",
    "print MeanT(Paths)\n",
    "\n",
    "# Part E\n",
    "\n",
    "#Function for the expected value of N\n",
    "def PMFT(Paths, t):\n",
    "    is_t=[]\n",
    "    for element in Paths:\n",
    "        #Creating a list of boolean to count the number of times that T=t\n",
    "        is_t.append((len(element)-1)==t)\n",
    "    #We return the mean to get a MC approximation of the probability\n",
    "    return np.mean(is_t)\n",
    "#Printing the value for t = sample mean for the generated paths\n",
    "#For this process t = 13\n",
    "print PMFT(Paths,13)\n",
    "\n",
    "# Part F\n",
    "\n",
    "#Array of the value for t\n",
    "tValues=range(0,50,1)\n",
    "#Array of the value for the PMF\n",
    "PMFValues = [PMFT(Paths,t) for t in range(0,50,1)]\n",
    "\n",
    "plt.plot(tValues, PMFValues)\n",
    "plt.title(\"PMF of T\")\n",
    "plt.xlabel(\"t\")\n",
    "plt.ylabel(\"PMF(t)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy;\n",
    "import math;\n",
    "from pylab import *;\n",
    "import sys;\n",
    "from matplotlib.colors import ColorConverter\n",
    "\n",
    "plot_portals = 1\n",
    "\n",
    "def self_omit(cluster_id, current_cluster_id):\n",
    "\tif cluster_id < current_cluster_id:\n",
    "\t\treturn cluster_id\n",
    "\telse:\n",
    "\t\treturn cluster_id + 1\n",
    "\n",
    "def main():\n",
    "\tif len(sys.argv) < 2:\n",
    "\t\tprint \"Error: not enough arguments.\"\n",
    "\t\tprint \"Usage: python plot.py embedding_file {tag_file tag_hash_file topTagCount=3}\"\n",
    "\t\tsys.exit(1)\n",
    "\t\t\n",
    "\tebdfilename = sys.argv[1];\n",
    "\tif len(sys.argv)>2:\n",
    "\t\tdoTags=1;\n",
    "\t\ttagFilename=sys.argv[2];\n",
    "\t\ttagHashFilename=sys.argv[3];\n",
    "\telse:\n",
    "\t\tdoTags=0;\n",
    "\t\t\n",
    "\tif len(sys.argv)==5:\n",
    "\t\ttopTagCount=int(sys.argv[4]);\n",
    "\telse:\n",
    "\t\ttopTagCount=3;\n",
    "\t\t    \n",
    "\t# read ebd header\n",
    "\tf=open(ebdfilename, 'r');\n",
    "\ttokens=f.readline().split(' ');  \n",
    "\tnumClusters=int(tokens[1]);    \n",
    "\ttokens=f.readline().split(' ');  \n",
    "\tnumSongs=int(tokens[1]);\n",
    "\ttokens=f.readline().split(' ');  \n",
    "\tdimensions=int(tokens[1]);\n",
    "\tif dimensions != 2:\n",
    "\t\tprint \"Error: can only plot embedding file with dimensionality 2.\"\n",
    "\t\tsys.exit(1)\n",
    "\ttokens=f.readline().split(' ');  \n",
    "\tbias_enabled=int(tokens[1]);\n",
    "\ttokens=f.readline().split(' ');  \n",
    "\tinter_cluster_transition_type=int(tokens[1]);\n",
    "\tnumPortals = 0\n",
    "\tif inter_cluster_transition_type == 3 or inter_cluster_transition_type == 4 or inter_cluster_transition_type == 5 or inter_cluster_transition_type == 6:\n",
    "\t\ttokens=f.readline().split(' ');  \n",
    "\t\tnumPortals=int(tokens[1]);\n",
    "\n",
    "\n",
    "\t# read cluster membership for each song\n",
    "\ttokens=f.readline().split(' ');\n",
    "\tclusters=numpy.zeros((numSongs, 1));\n",
    "\tclusterSizes=numpy.zeros((numClusters, 1));\n",
    "\tfor i in range(1, numSongs+1):\n",
    "\t\tcluster=int(tokens[i]);\n",
    "\t\tclusters[i-1]=cluster;\n",
    "\t\tclusterSizes[cluster]=clusterSizes[cluster]+1;\n",
    "\n",
    "\t# read coordinates for each song\n",
    "\tif inter_cluster_transition_type == 0:\n",
    "\t\tcoords=numpy.zeros((numSongs+numClusters*numClusters, 2));\n",
    "\telif inter_cluster_transition_type == 1:\n",
    "\t\tcoords=numpy.zeros((numSongs+2 * numClusters * (numClusters - 1), 2));\n",
    "\telif inter_cluster_transition_type == 3 or inter_cluster_transition_type == 4 or inter_cluster_transition_type == 6:\n",
    "\t\tcoords=numpy.zeros((numSongs + numPortals * numClusters, 2));\n",
    "\telif inter_cluster_transition_type == 5:\n",
    "\t\tcoords=numpy.zeros((numSongs + 2 * numPortals * numClusters, 2));\n",
    "\n",
    "\tcounter=0;\n",
    "\tfor i in range(numClusters):\n",
    "\t\tline=f.readline();\n",
    "\t\tif bias_enabled:\n",
    "\t\t\tline=f.readline();\n",
    "\t\tif inter_cluster_transition_type == 0:\n",
    "\t\t\ttemp_range =clusterSizes[i] + numClusters\n",
    "\t\telif inter_cluster_transition_type == 1:\n",
    "\t\t\ttemp_range =clusterSizes[i] + 2 * (numClusters - 1)\n",
    "\t\telif inter_cluster_transition_type == 3 or inter_cluster_transition_type == 4 or inter_cluster_transition_type == 6:\n",
    "\t\t\ttemp_range = clusterSizes[i] + numPortals\n",
    "\t\telif inter_cluster_transition_type == 5:\n",
    "\t\t\ttemp_range = clusterSizes[i] + 2 * numPortals\n",
    "\n",
    "\t\tfor j in range(temp_range):\n",
    "\t\t\ttokens=f.readline().split(' ');        \n",
    "\t\t\tfor k in range(dimensions):\n",
    "\t\t\t\tcoords[counter, k]=float(tokens[k]);            \n",
    "\t\t\tcounter=counter+1;\n",
    "\tf.close();\n",
    "        \n",
    "\tif doTags:\n",
    "\t\t# read tag hash file\n",
    "\t\tf=open(tagHashFilename, 'r');\n",
    "\t\ttagHash=[];\n",
    "\t\twhile 1:\n",
    "\t\t\tline=f.readline();\n",
    "\t\t\tif not line:\n",
    "\t\t\t\tbreak;   \n",
    "\t\t\ttokens=line.split(', ');\n",
    "\t\t\ttagHash.append(tokens[1].strip('\\n'));\t\n",
    "\t\tf.close();\n",
    "\t\t\n",
    "\t\t# read tag file\n",
    "\t\tnumTags=len(tagHash);\n",
    "\t\ttagCountPerCluster=numpy.zeros((numTags, numClusters));\n",
    "\t\tf=open(tagFilename, 'r');\n",
    "\t\tfor i in range(numSongs):\n",
    "\t\t\tline=f.readline();\n",
    "\t\t\tif line=='#\\n':\n",
    "\t\t\t\tcontinue;\n",
    "\t\t\ttokens=line.split(' ');\n",
    "\t\t\tfor j in range(len(tokens)):\n",
    "\t\t\t\tcluster=int(clusters[i]);\n",
    "\t\t\t\ttag=int(tokens[j]);\t\t\t\t\t\t\n",
    "\t\t\t\ttagCountPerCluster[tag, cluster]+=1;\n",
    "\t\tf.close();    \n",
    "\t\t\n",
    "\t\t# find top N tags for each cluster\n",
    "\t\ttopTags=zeros((topTagCount, numClusters));\n",
    "\t\tfor i in range(numClusters):\n",
    "\t\t\tidx=argsort(tagCountPerCluster[:, i]);\t\t\n",
    "\t\t\tfor j in range(topTagCount):\n",
    "\t\t\t\ttopTags[j, i]=idx[numTags-j-1];\n",
    "\n",
    "\t# index positions for each cluster in coords\n",
    "\tcoordIdx=numpy.zeros((numClusters, 2));\n",
    "\tif inter_cluster_transition_type == 0:\n",
    "\t\tcoordIdx[0, 1]=clusterSizes[0]+numClusters-1;\n",
    "\telif inter_cluster_transition_type == 1:\n",
    "\t\tcoordIdx[0, 1]=clusterSizes[0]+ 2 * (numClusters - 1) - 1;\n",
    "\telif inter_cluster_transition_type == 3 or inter_cluster_transition_type == 4 or inter_cluster_transition_type == 6:\n",
    "\t\tcoordIdx[0, 1]=clusterSizes[0]+ numPortals - 1;\n",
    "\telif inter_cluster_transition_type == 5:\n",
    "\t\tcoordIdx[0, 1]=clusterSizes[0]+ 2 * numPortals - 1;\n",
    "\tfor i in range(1, numClusters):\n",
    "\t\tcoordIdx[i, 0]=coordIdx[i-1, 1]+1;\n",
    "\t\tif inter_cluster_transition_type == 0:\n",
    "\t\t\tcoordIdx[i, 1]=coordIdx[i, 0]+clusterSizes[i]+numClusters-1;    \n",
    "\t\telif inter_cluster_transition_type == 1:\n",
    "\t\t\tcoordIdx[i, 1]=coordIdx[i, 0]+clusterSizes[i]+ 2 * (numClusters - 1) - 1;    \n",
    "\t\telif inter_cluster_transition_type == 3 or inter_cluster_transition_type == 4 or inter_cluster_transition_type == 6:\n",
    "\t\t\tcoordIdx[i, 1]=coordIdx[i, 0]+clusterSizes[i]+ numPortals - 1;    \n",
    "\t\telif inter_cluster_transition_type == 5:\n",
    "\t\t\tcoordIdx[i, 1]=coordIdx[i, 0]+clusterSizes[i]+ 2 * numPortals - 1;    \n",
    "\n",
    "\t# scatter plot\n",
    "\tfig=figure();\n",
    "\tarea1=pi*4**2;area2=pi*4**2;\n",
    "\tM=floor(sqrt(numClusters));N=ceil(numClusters/M);\n",
    "\tfor i in range(numClusters):\n",
    "\t\tstartIdx=int(coordIdx[i, 0]);endIdx=int(coordIdx[i, 1]);\n",
    "\t\tX=coords[range(startIdx, endIdx+1), 0].copy();\n",
    "\t\tY=coords[range(startIdx, endIdx+1), 1].copy();\n",
    "\n",
    "\t\tsubplot(M, N, i+1);\n",
    "\t\ttitleStr='Cluster '+str(i);\n",
    "\t\tif doTags:\n",
    "\t\t\ttitleStr+=', Top '+str(topTagCount)+' tags:\\n';\n",
    "\t\t\tfor j in range(int(topTagCount)):\n",
    "\t\t\t\tif j==topTagCount-1:\n",
    "\t\t\t\t\ttitleStr+=tagHash[int(topTags[j, i])];\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\ttitleStr+=tagHash[int(topTags[j, i])]+', ';\n",
    "\t\t\t\t\t\n",
    "\t\tmyfont = { 'fontsize':10 }\n",
    "\t\ttitle(titleStr, **myfont);\t\t\n",
    "\t\thold(1);\t\t\n",
    "\n",
    "\n",
    "\t\tcc = ColorConverter()\n",
    "\t\t#songcolor = cc.to_rgb(\"#9932CC\")\n",
    "\t\tsongcolor = cc.to_rgb(\"#BBBBBB\")\n",
    "\t\tentrycolor = cc.to_rgb('b')\n",
    "\t\texitcolor = cc.to_rgb(\"#FF7F00\");\n",
    "\n",
    "\t\tif inter_cluster_transition_type == 0:\n",
    "\t\t\tscatter(X[range(numClusters, X.shape[0])], Y[range(numClusters, Y.shape[0])], s=area2, marker='.', c=  songcolor, lw=0);\t\t\n",
    "\t\t\tscatter(X[range(numClusters)], Y[range(numClusters)], s=0, marker='^', c='b');\t\t\n",
    "\t\t\tXlist = list(X[range(numClusters)])\n",
    "\t\t\tYlist = list(Y[range(numClusters)]) \n",
    "\t\t\tlabels = map(lambda x: str(x), range(len(Xlist)));\n",
    "\t\t\tif plot_portals:\n",
    "\t\t\t\tfor label, x, y in zip(labels, Xlist, Ylist):\n",
    "\t\t\t\t\tif int(label) == i:\n",
    "\t\t\t\t\t\tannotate(label, xy = (x, y), textcoords = \"data\", color=entrycolor, size = 14)\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\tannotate(label, xy = (x, y), textcoords = \"data\", color=exitcolor, size = 14)\n",
    "\t\telif inter_cluster_transition_type == 1:\n",
    "\t\t\tscatter(X[range(2 * (numClusters - 1), X.shape[0])], Y[range(2 * (numClusters - 1), Y.shape[0])], s=area2, marker='.', c =  songcolor, lw=0);\t\t\n",
    "\t\t\tscatter(X[range(2 * (numClusters - 1))], Y[range(2 * (numClusters - 1))], s=0, marker='^', c='b');\n",
    "\t\t\tXlist_entry = list(X[range(numClusters - 1)])\n",
    "\t\t\tYlist_entry = list(Y[range(numClusters - 1)]) \n",
    "\t\t\tXlist_exit = list(X[range(numClusters - 1, 2 * (numClusters - 1))])\n",
    "\t\t\tYlist_exit = list(Y[range(numClusters - 1, 2 * (numClusters - 1))]) \n",
    "\t\t\tlabels = map(lambda x: str(self_omit(x, i)), range(len(Xlist_entry)));\n",
    "\n",
    "\t\t\tif plot_portals:\n",
    "\t\t\t\tfor label, x, y in zip(labels, Xlist_entry, Ylist_entry):\n",
    "\t\t\t\t\tannotate(label, xy = (x, y), textcoords = \"data\", color=entrycolor, size = 14)\n",
    "\t\t\t\tfor label, x, y in zip(labels, Xlist_exit, Ylist_exit):\n",
    "\t\t\t\t\tannotate(label, xy = (x, y), textcoords = \"data\", color=exitcolor, size = 14)\n",
    "\t\telif inter_cluster_transition_type == 3 or inter_cluster_transition_type == 4 or inter_cluster_transition_type == 6:\n",
    "\t\t\tscatter(X[range(numPortals, X.shape[0])], Y[range(numPortals, Y.shape[0])], s=area2, marker='.', c=  songcolor, lw=0);\t\t\n",
    "\t\t\tscatter(X[range(numPortals)], Y[range(numPortals)], s=20, marker='.', c='b', edgecolor = 'b');\t\t\n",
    "\t\telif inter_cluster_transition_type == 5:\n",
    "\t\t\tscatter(X[range(2 * numPortals, X.shape[0])], Y[range(2 * numPortals, Y.shape[0])], s=area2, marker='.', c=  songcolor, lw=0);\t\t\n",
    "\t\t\tscatter(X[range(numPortals)], Y[range(numPortals)], s=area2, marker='.', c= entrycolor, edgecolor = entrycolor);\t\t\n",
    "\t\t\tscatter(X[range(numPortals, 2 * numPortals)], Y[range(numPortals, 2 * numPortals)], s=area2, marker='.', c= exitcolor, edgecolor = exitcolor);\t\t\n",
    "\n",
    "\n",
    "\t\thold(0);\n",
    "\tsubplots_adjust(left=None, bottom=None, right=None, top=None, wspace=None, hspace=0.5)\n",
    "\t#savefig(bbox_inches='tight')\n",
    "\tshow();\n",
    "\n",
    "if(__name__ == \"__main__\"):\n",
    "\tmain()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}